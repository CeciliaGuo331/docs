---
title: 深度学习原理与PyTorch实战
date: 2025-06-28
details: 预习
---

# 深度学习原理与PyTorch实战

## 1. 深度学习简介与核心概念

### 1.1 什么是深度学习？

深度学习是一种利用深度人工神经网络进行自动分类、预测和学习的技术。它与人工智能和机器学习的关系是层次递进的：人工智能覆盖面广，机器学习是人工智能的一个重要分支，而深度学习是机器学习中使用深度人工神经网络的一种特殊技术。

- 深度人工神经网络：通常认为超过三层的神经网络即可称为深度神经网络。目前已能实现深达1000多层的人工神经网络（1.1节）。

- 反向传播算法：是人工神经网络的核心技术，能够精确调整网络中出现问题的部件，快速降低分类或预测的错误率，使其在诸多机器学习算法中胜出（1.1节）。

- 特征学习：深度学习的本质。它能自动从原始数据中提炼出不同层次的特征，无需手动干预，大大解放了生产力。例如，CNN在图像识别中能自动提炼低尺度特征（边缘、棱角）和高尺度特征（整张人脸）（1.4.1节）。

### 1.2 PyTorch与动态计算图

PyTorch是一个流行的深度学习框架，其核心优势在于支持动态计算图。

- 动态计算图：将正向计算过程步骤记录下来，只要运算可微分，就能沿着计算图路径对任意变量求导，进而自动计算每个变量的梯度。这大幅提升了构建神经计算系统的效率，解决了之前针对不同网络架构需编写不同反向传播算法的难题（2.2.3节）。

- 自动微分：PyTorch通过.grad_fn属性记录运算过程，构成计算图。运算结果存储在data中。每一步运算，PyTorch会添加新节点到动态计算图中并与上一步节点相连（2.2.3节）。

- 梯度信息：即导数数值，只有叶节点（自变量）才能计算梯度信息，非叶节点（中间变量）不需要计算（2.2.3节）。

### 1.3 机器学习基本术语（以房价预测为例）

通过房价预测的线性回归模型，源材料总结了深度学习中的基本概念：

- 模型：对数据预测原理的基本假设，如一条直线或更复杂的神经网络（2.3.5节）。

- 拟合：将模型应用于训练数据并试图达到最佳匹配的过程（2.3.5节）。

- 特征变量：模型的自变量集合，用于进行预测（2.3.5节）。

- 目标变量：模型要去拟合的目标（2.3.5节）。

- 参数：模型中通过训练调整以改善拟合效果的变量，如线性回归中的权重和偏置，或神经网络的权重和偏置（2.3.5节）。

- 损失函数：衡量模型质量的函数，通过优化该函数求出最优参数组合（2.3.5节）。

- 训练：反复调整模型中参数的过程（2.3.5节）。

- 测试：检验训练好的模型的过程（2.3.5节）。

- 样本、训练集、测试集：数据点、用于训练的数据集、用于检验模型的数据集（2.3.5节）。

- 梯度下降算法：根据梯度信息更新参数的简单有效算法，用于求解函数最小值（2.3.2节，2.3.5节）。

- 训练迭代：反复利用梯度下降算法的循环过程（2.3.5节）。

- 超参数：不会在训练中调节的参数，如多项式方程的最高幂次，或神经网络每层的神经元个数（2.3.5节）。

## 2. 神经网络结构与实践

### 2.1 人工神经网络工作原理

人工神经网络（ANN）受人脑生物神经网络启发，善于从输入数据和标签中学习映射关系，完成预测或分类。

- 通用拟合器：ANN可以拟合任意函数或映射（3.2.1节）。

- 前馈神经网络：常用的一种ANN，包含输入层、隐含层和输出层。隐含层可包含多层，构成深度神经网络（3.2.1节）。

- 运行过程：

    - 前馈预测：信号从输入单元输入，与连边权重相乘，在隐含单元汇总、激活后输出，最终得到整个神经网络的输出（3.2.1节）。

    - 反馈学习：输出神经元计算预测误差，误差沿网络反向传播（反向传播算法），根据节点误差计算连边权重更新量，完成网络学习与调整（3.2.1节）。

- 人工神经元：模拟生物神经细胞的信号传递与激活。通过调整权重（w）和偏置（b）等参数，可以调节映射函数的形状。sigmoid函数是一种常用激活函数（3.2.2节）。

- 通用逼近定理：理论证明，有限多的隐含神经元可以逼近任意有限区间内的曲线（3.2.3节）。

### 2.2 过拟合及其解决方法

过拟合是指模型在训练数据上表现良好，但在全新的测试数据上表现不佳。

- 原因：模型过度学习了训练数据中的噪声或不相关的模式，而非真实数据模式。例如，在共享单车预测中，使用数据下标作为特征导致严重过拟合（3.2.6节）。

- 启示：在面对大数据时，数据背后的意义往往能指导更快速地找到分析捷径，不能一味追求人工智能技术而忽略实际问题背景（3.2.6节）。

- 解决方法：

    - 归一化处理：将输入数据范围归一化，如将数值范围变为0~1，可加速训练并改善拟合效果（3.2.5节）。

    - 选择正确特征变量：预测共享单车数量应依赖天气、风速、星期几、是否节假日等因素，而非数据下标（3.2.6节，3.3节）。

    - 划分数据集：将数据划分为训练集、测试集和校验集。校验集是调节超参数、判断是否过拟合的重要标准（4.6节）。

    - 批处理：将数据切分成批次进行训练，既加速程序运行，又使神经网络稳步调节参数（3.5节）。

    - 增加训练数据：对于特定条件（如圣诞节）的预测不准确，可增加包含该条件的训练数据（3.6节Q&A）。

    - Dropout：在训练阶段随机关闭部分神经元，校验和测试时打开，以防止过拟合（5.2.3节）。

### 2.3 分类问题与Softmax函数

神经网络不仅用于预测，也广泛应用于分类。

- Softmax函数：在分类任务中，输出层通常使用Softmax函数将神经元输出值转换为概率分布。输出值介于[0,1]之间，且所有项之和等于1，可解释为当前样本被归为某一类别的概率（4.3节）。

- 词袋模型（Bag-of-Words）：将一句话中的所有单词放入词袋中，忽略语法、语义和顺序，只关心每个单词的数量，从而建立句子的向量表示。优势是简单便利，劣势是相关性差，无法准确表征词与词之间的关系（4.4节，4.7节Q&A）。

    - 改进：可建立停用词列表丢弃无意义词语，或参考TF-IDF指标衡量单词重要程度（4.7节Q&A）。

## 3. 卷积神经网络（CNN）

### 3.1 卷积神经网络的工作原理

CNN是一种特殊的前馈神经网络，特别适用于图像处理。

- 组成：由卷积层、池化层和全连接层交替组成。信息从左侧图像输入，经过层层加工，最终输出分类概率（5.1节）。

- 卷积运算：本质上是一个模板匹配过程。卷积核（过滤器）在原始图像上扫描和匹配相似区域，生成特征图。特征图上像素灰度高低代表匹配程度。数学上表现为卷积核与图像区域的内积运算（5.1.2节）。

    - 卷积核：可看作一张小图，其中的数值是卷积层神经网络的权重（5.1.2节）。

    - 特征图：卷积运算结果，表示模板与原始图像相应位置的匹配程度（5.1.2节）。

- 池化运算：对特征图进行降采样，通常有最大池化（取窗口内最大像素值）和平均池化（取窗口内像素平均值）。目的在于保留重要特征同时减少参数量，增加计算效率，并使特征具有尺度不变性（5.1.3节）。

- 参数效率：CNN的参数数量远少于传统全连接网络，学习更高效，易于叠加组成深层网络（5.1.5节）。

- 反向传播：CNN有适合其卷积和池化运算的特殊反向传播算法（5.1.6节）。

## 4. 迁移学习

### 4.1 迁移学习的概念与意义

迁移学习是将一个领域训练好的机器学习模型应用到另一个领域，解决训练数据缺失的问题，提高模型利用率。

- 核心思想：机器进行“举一反三”的过程，将已学知识应用于新任务。与监督学习不同，迁移学习允许训练集和测试集数据具有不同分布（6.1.1节）。

- 重要性：吴恩达认为迁移学习是继监督学习之后，最有活力和前途的领域，能减轻对数据的依赖（6.1.3节）。

- 商业模式：大公司训练大型泛化模型，小公司利用迁移学习将其应用到特定垂直领域数据上，实现优势互补（6.1.3节）。

- 神经网络实现：将训练好的神经网络从中间切开，再拼接其他网络。因为深度神经网络不同层学习到不同尺度的信息，可将低层特征提取器视为软件模块进行复用（6.1.4节）。例如，将识别猫狗的CNN的卷积部分迁移到新的全连接网络，可用于区分老虎和狮子（6.1.4节）。

- 应用案例：利用卫星遥感影像数据预测贫困地区。由于贫困地区标注数据稀少，可先训练CNN用遥感图像预测夜光亮度，然后将训练好的网络迁移到预测贫困地区的任务中（6.2.2节，6.2.3节）。

## 5. 图像生成与生成对抗网络（GAN）

### 5.1 反卷积与反池化

在图像生成中，需要将特征图尺寸放大，这需要反卷积和反池化操作。

- 反卷积：数学上仍然是卷积，但能使图像尺寸变大。其定义是根据反向传播算法给出的：第l-1层的误差图是用这层的卷积核的翻转（反卷积的卷积核）在第l层的误差图上做卷积得到的（8.1.2节）。

- 反池化：反池化有多种方法，其中一种是通过调整卷积运算的“步伐”（striding）参数实现。步伐越大，输出特征图越小，而反过来调整可使图像变大（8.1.3节）。

### 5.2 图像生成模型演进

从最小均方误差模型到生成对抗网络，图像生成技术不断发展。

- 最小均方误差（MSE）模型：直接优化均方误差会导致生成的图像模糊，因为模型学习的是平均手写数字图像，差异大的样本会相互抵消（8.2.3节）。

- 生成器-识别器模型：引入一个识别器来矫正生成器。生成器生成的图像输入识别器，识别器判断其是否为正确数字。但存在对抗样本问题：识别器可能被骗过但人眼仍能识别出图像的模糊性（8.3节）。

- 生成对抗网络（GAN）：
    
    - 核心思想：训练一个判别器来区分真实图像和生成图像。生成器致力于生成能“骗过”判别器的图像，判别器致力于区分真实和生成图像（8.3节）。

    - 伊恩·古德菲洛：GAN的发明者，天才青年科学家（8.3节）。

## 6. 序列生成模型与循环神经网络（RNN/LSTM）

### 6.1 序列生成问题

序列生成通常转化为序列预测问题，即用序列前面的字符预测下一个字符，从而得到大量训练数据对。

- 基本思路：先学习（训练模型预测下一个字符），再生成（给定种子序列，模型不断预测后续字符）（10.1节）。

- 挑战：传统前馈神经网络（如NPLM）只能应用于固定长度输入（N-gram模型），无法处理输入长度不固定的情况。长程相关性问题导致N-gram模型难以捕捉远距离模式（10.1节）。

### 6.2 循环神经网络（RNN）

RNN通过隐含层内部的连接，具备记忆能力，能处理序列数据。

- 结构特点：当前时刻隐含层输出（h_t）不仅与输入层信号（x_t）有关，还与上一时刻隐含层输出（h_{t-1}）有关。这种依赖关系使RNN在相同输入下可能产生不同输出，体现了记忆能力（10.2节）。

- 运行：包含前馈预测和反向学习两个阶段。每一时刻的运行状态会影响下一时刻。误差通过反向传播调整权重（10.2节）。

- 局限：由于非线性激活函数导致信号在长时间运行中不断衰减，RNN的记忆能力有限，无法学习和记忆长时间模式（10.2节，10.5节）。

### 6.3 长短期记忆网络（LSTM）

LSTM是RNN的改进版本，通过门控机制解决了RNN的长期记忆问题。

- 核心改进：LSTM单元内部包含一个“蓄水池”（cell）和三个门控开关：输入门、遗忘门和输出门。这些门通过神经元控制，调节信息流入、流出和遗忘，实现精准的信息记忆（10.2节，10.5节）。

- 门控机制：

    - 输入门：控制外界信息流入“蓄水池”。

    - 遗忘门：控制“蓄水池”中信息的耗散。
    
    - 输出门：控制“蓄水池”中信息流出。

- 记忆原理：cell状态存储信息，门控信号（0到1之间的数字）控制信息的保留和更新。权重参数通过反向传播动态调整，LSTM单元能学会根据输入信号控制门开关（10.2节）。

- 应用：成功用于MIDI音乐作曲机，将MIDI文件拆解为序列，训练LSTM网络，生成新序列（10.4节）。

### 6.4 门控循环单元（GRU）

GRU是LSTM的一种简化变体，没有输出门和独立的cell状态，但同样具有门控机制。

- 结构简化：仅有两个门：更新门（控制是否更新当前隐含状态）和重置门（控制是否用新输入或独立考虑输入）。其核心思想是，想要大量新信息就遗忘旧信息，想保留旧信息就遗忘新信息（11.4.1节）。

- 优势：相较LSTM，GRU参数更少，计算效率更高。

## 7. 神经机器翻译与Transformer

### 7.1 编码-解码模型

神经机器翻译的重大突破始于2014年编码-解码模型的发明。

- 架构：针对两个文本序列进行建模，输入序列1，模型自动生成序列2。例如，将英文句子作为输入，生成对应的法语翻译（11.1节）。

- 工作流程：

    - 分词与词嵌入：将句子切分成以token（词或子词）为基本单位的序列，并通过词嵌入层转换为向量。

    - 编码器：接收词向量，输出一个向量作为对原文的理解。

    - 解码器：根据编码器的理解，逐词输出翻译（11.1节）。

- 注意力机制：2015年引入，大幅提升编码-解码模型的翻译精度并支持长句翻译。它允许解码器在生成每个词时，能够关注编码器输出向量中与当前生成词最相关的部分（11.3节）。

### 7.2 Transformer模型

Transformer是一种完全基于注意力机制的深度学习模型，在机器翻译等任务中表现卓越。

- 核心思想：摒弃了传统的RNN和CNN结构，完全依赖自注意力机制（Self-Attention）来处理输入序列。

- 位置编码（Position Encoding）：由于Transformer不包含循环和卷积，无法捕捉序列顺序信息，因此需要添加位置编码来表示词语在序列中的相对或绝对位置（12.2节）。

- 自注意力模块：

    - 多头注意力（Multi-Head Attention）：将大词向量通过变换化为若干组小向量（头），每个头独立进行自注意力计算，然后将各头结果拼接（12.3.2节）。

    - Q、K、V向量：每个输入向量一分为三，生成查询向量（Q）、关键字向量（K）和值向量（V）。Q与K进行点乘计算相似度，经Softmax归一化后得到注意力矩阵，再与V加权求和，获得token的新表示（12.3.2节）。

- 残差连接与层归一化：解决大型网络训练中的梯度消失和不稳定问题，加速模型收敛，提升网络表现（12.3.4节）。

- 逐点计算的前向网络层（FFN）：在自注意力层之后，对输出向量进行两次矩阵变换，有助于模型性能提升，可能类似于记忆层（12.3.5节）。

- 输入单位粒度：采用无监督的**字节对编码（BPE）**算法将单词拆分成子词，降低词表外（UNK）词语的出现频率，提高翻译效果（12.4.1节）。

### 7.3 预训练语言模型（GPT与BERT）

Transformer架构为预训练语言模型奠定了基础，极大地推动了自然语言处理的发展。

- 预训练-微调框架：解决自然语言处理问题分为两个阶段：以语言模型任务为目标的预训练阶段和以实际任务为目标的微调阶段（13.2节）。

- GPT (Generative Pre-trained Transformer)：

    - 架构：类似于Transformer解码器，但删去了编码-解码注意力层，只针对单语建模（13.2.1节）。

    - 预训练任务：自回归语言模型，从前到后逐个字记忆，预测下一个词。在文本生成方面更具创造力（13.1节）。

    - GPT-3：利用巨量数据预训练，实现“少样本/无样本学习”，无需多余训练即可举一反三（13.1节）。

- BERT (Bidirectional Encoder Representations from Transformers)：
    
    - 架构：类似于Transformer编码器，使用双向Transformer来学习上下文信息（源材料中未详细描述BERT架构，但暗示其基于Transformer编码器）。

    - 预训练任务：带掩码的语言模型，从句子中随机挖去若干词，凭借对上下文的理解填写正确答案。善于理解上下文信息（13.1节）。

    - 应用：已被谷歌搜索使用，旨在让搜索引擎更懂用户，搜到更精准答案（13.1节）。

## 8. 图神经网络（GNN）

### 8.1 图网络的基本概念

图网络是一种以图作为输入，能捕捉节点之间关系信息的深度学习模型。

- 图的表示：

    - 节点信息：每个节点的信息可以用一个向量表示，所有节点信息可用矩阵表示（14.1节）。

    - 连边信息：常用邻接矩阵表示，矩阵元素非0即1，表示节点间是否存在连边（14.1节）。

- 优势：图网络除了关注节点本身的特征，还会抓取该节点在图上的邻居信息（信息聚合）。邻居信息能从另一个角度描述节点状态，有时比个体自身信息更能有效定义节点（14.1.2节）。例如，解决论文分类任务时，图网络可整合引文信息，避免词袋模型误分类问题（14.1.2节）。

- 基本任务：

    - 节点分类：为图中的节点打标签，如论文分类（14.1.3节）。

    - 链路预测：推测网络中尚未产生连边的两个节点产生连边的可能性，如社交关系推荐（14.1.3节）。

    - 网络生成：根据已有网络数据生成类似结构，如药物生成（14.1.3节）。

### 8.2 图卷积网络（GCN）

GCN是图神经网络的一种，用于处理图结构数据。

- 工作流程：将节点信息和连边关系输入GCN，GCN通过聚合邻居信息更新节点信息，最终预测节点的标签（14.2节）。

- 聚合函数改进：

    - 将节点自身信息也作为邻居信息处理（将邻接矩阵对角线设为1）。

    - 对聚合后的结果进行标准化，解决邻居多导致信息迅速膨胀问题（通过除以节点度数）（14.2节）。

- 人体姿态识别：可将人体关节视作节点，骨头视作连边，构建图结构。通过训练GCN区分不同姿态，如“走”或“跑”（14.4节）。

## 9. 强化学习

### 9.1 强化学习的核心概念与特点

强化学习（RL）是让主体在与环境的互动中积累更多回报的有效算法。

- 基本要素：

    - 主体（agent）：学习者或决策者。

    - 环境（environment）：主体所处的外部世界。
    
    - 状态（state）：主体所处的环境情况。

    - 动作（action）：主体可执行的行动。

    - 回报（reward）：执行动作后环境对主体的反馈（15.1.1节）。

- 特点：

    - 边做边学：学习和行动无法明显区分，主体必须平衡探索（获取新知识）和利用（利用现有知识）。这更像人类面临的真实世界（15.1.1节）。
    
    - 综合考虑短期与长期回报：环境反馈不一定即时，主体需学习长远的策略，避免短期高回报但长期受惩罚的情况（15.1.1节）。

### 9.2 强化学习的应用场景

尽管挑战巨大，强化学习应用领域广泛。

- 棋类博弈：从早期跳棋程序（Arthur Samuel，时间差分算法，Q学习算法前身）到AlphaGo Zero（从零开始自我对弈，战胜人类世界冠军），强化学习在棋类博弈上取得巨大突破（15.1.2节）。

- 电子游戏：将游戏视为主体与环境博弈的容器，智能算法通过观察像素画面而非了解规则来学习游戏策略，表现超越人类玩家（15.1.2节）。

- 传统控制：如机器人行走轨迹控制、飞行器自动控制、机械手臂自动控制等（15.1.2节）。

- 聊天对话程序：用户行为作为环境，聊天持续视为奖励，退出视为惩罚，通过强化学习改进对话策略（15.1.2节）。

- 推荐系统：用户点击、评价等动作作为环境反馈，优化推荐策略（15.1.2节）。

### 9.3 Q学习算法与深度Q学习网络（DQN）

- Q学习算法：

    - 核心思想：定义一个价值评估函数Q(s, a)，评估在状态s下执行动作a的好坏。主体在每个周期选择使Q值最大的行动（15.2.1节）。

    - Q函数的学习：通过迭代公式更新Q值，使其与环境反馈一致，并与未来估值一致（“时间差分算法”精华）。Q(s, a)的更新量与环境反馈+未来最大Q值与当前Q值的差值成正比（15.2.1节）。

- 深度Q学习网络（DQN）：
    
    - 改进：利用深度神经网络替代传统Q学习中存储Q值的大表格，解决了内存浪费和更新效率低的问题（15.2.2节）。
    
    - DeepMind的里程碑工作：2015年发表论文，将深度学习与强化学习结合，构建端到端学习算法，在雅达利游戏上表现超越人类玩家（15.2.2节）。

    - Q函数建模：将Q函数视为一个神经网络，输入状态和可能的动作，输出实数值（Q值）。DQN网络通常采用深度卷积架构，输入层读取游戏画面帧（15.2.2节）。

    - 学习机制：以Q学习迭代公式的右侧（即r + γ * max(Q(s', a'))）作为监督目标来训练神经网络。DQN的目标函数需要使用DQN本身来计算（15.2.3节）。

    - 训练数据：来自游戏机制本身。游戏每进行一步，产生一个五元组(s, a, r, s', done)，存储在经验回放池（replay memory）中。训练时从回放池中随机抽取批次数据进行训练（15.2.4节）。

## 10. 通用人工智能与哥德尔机

### 10.1 通用人工智能（AGI）

AGI指能够处理任何智力任务的机器，像人类一样学习和理解，而非仅限于特定任务。

- AIXI：由马库斯·胡特尔提出的通用智能体的数学理论，它能最优地完成任何决策并与环境互动。AIXI理论证明存在一个最优的智能体（15.3节）。

- 哥德尔机（Gödel Machine）：由LSTM发明者尤根·斯提姆哈勃提出的AIXI升级版。包含求解器（solver，类似AIXI）和搜索器（searcher）。搜索器对自身软硬件、环境进行模拟搜索，找到更优解决方案并自行升级进化（15.3节）。

- 自指能力：哥德尔机以一种自指的方式进行自身模拟并升级，具备自我觉知（self-awareness）能力。这与普通机器学习的自我更新不同，更像有意识的自我修改（15.3节）。

- 潜在影响：哥德尔机可能带来智能爆炸，未来发展不可预测（15.3节）。